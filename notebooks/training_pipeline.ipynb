{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thanoz/.virtualenvs/mdx/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "import torch.optim as optim\n",
    "\n",
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "from mdx.models.utils.model_utils import get_model_class\n",
    "from mdx.dataloaders.audiodataloader import AudioDataset\n",
    "\n",
    "from torchsummary import summary\n",
    "import torchmetrics\n",
    "from torchmetrics.audio import SignalDistortionRatio, SignalNoiseRatio, ScaleInvariantSignalDistortionRatio\n",
    "from torchmetrics.regression import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1996\n"
     ]
    }
   ],
   "source": [
    "from train_pl import Configuration\n",
    "config = Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1996\n"
     ]
    }
   ],
   "source": [
    "# Function for setting the seed\n",
    "pl.seed_everything(Configuration.general.seed)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.determinstic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:45<00:00, 22.51s/it]\n"
     ]
    }
   ],
   "source": [
    "ds = AudioDataset(\n",
    "    paths=config.dataset.paths,\n",
    "    sampling_rate=config.dataset.sampling_rate,\n",
    "    sources=config.dataset.sources,\n",
    "    targets=config.dataset.targets,\n",
    "    n_samples=44100*2,\n",
    "    debug=True,\n",
    "    pre_init=True,\n",
    "    )\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=4, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': tensor([[[-0.0087, -0.0154, -0.0345,  ...,  0.2963,  0.3022,  0.3101],\n",
       "          [-0.0343, -0.0543, -0.0886,  ...,  0.2556,  0.2747,  0.2947]],\n",
       " \n",
       "         [[ 0.2423,  0.1734,  0.1118,  ...,  0.0082, -0.0134, -0.0425],\n",
       "          [-0.0085, -0.0552, -0.0240,  ...,  0.0961,  0.0849,  0.0656]],\n",
       " \n",
       "         [[ 0.0223, -0.0102, -0.0122,  ...,  0.0773,  0.1697,  0.2008],\n",
       "          [ 0.0100, -0.0190, -0.0170,  ...,  0.1178,  0.1763,  0.2176]],\n",
       " \n",
       "         [[-0.0995, -0.0969, -0.0938,  ..., -0.0335, -0.0140,  0.0041],\n",
       "          [-0.0241, -0.0251, -0.0246,  ..., -0.0133, -0.0194, -0.0166]]]),\n",
       " 'output': {'bass': tensor([[[-0.0777, -0.0774, -0.0771,  ..., -0.0045, -0.0045, -0.0045],\n",
       "           [-0.0777, -0.0774, -0.0771,  ..., -0.0045, -0.0045, -0.0045]],\n",
       "  \n",
       "          [[ 0.0602,  0.0600,  0.0598,  ...,  0.0089,  0.0091,  0.0091],\n",
       "           [ 0.0611,  0.0609,  0.0608,  ...,  0.0085,  0.0086,  0.0087]],\n",
       "  \n",
       "          [[ 0.0040,  0.0041,  0.0041,  ...,  0.0151,  0.0149,  0.0147],\n",
       "           [ 0.0040,  0.0041,  0.0041,  ...,  0.0151,  0.0149,  0.0147]],\n",
       "  \n",
       "          [[-0.1030, -0.1032, -0.1035,  ...,  0.0010,  0.0010,  0.0010],\n",
       "           [-0.1030, -0.1032, -0.1035,  ...,  0.0010,  0.0010,  0.0010]]]),\n",
       "  'drums': tensor([[[ 0.0081,  0.0120,  0.0132,  ...,  0.1499,  0.1505,  0.1512],\n",
       "           [-0.0045,  0.0010,  0.0006,  ...,  0.1538,  0.1543,  0.1546]],\n",
       "  \n",
       "          [[ 0.1147,  0.0778,  0.0652,  ..., -0.0388, -0.0399, -0.0477],\n",
       "           [ 0.0350,  0.0134,  0.0244,  ..., -0.0459, -0.0569, -0.0716]],\n",
       "  \n",
       "          [[ 0.0198, -0.0101, -0.0099,  ...,  0.0085,  0.0977,  0.1282],\n",
       "           [ 0.0086, -0.0197, -0.0174,  ...,  0.0149,  0.0673,  0.1024]],\n",
       "  \n",
       "          [[ 0.0035,  0.0064,  0.0097,  ..., -0.0344, -0.0150,  0.0031],\n",
       "           [ 0.0789,  0.0781,  0.0789,  ..., -0.0142, -0.0204, -0.0175]]]),\n",
       "  'other': tensor([[[ 3.9825e-02,  3.6224e-02,  3.5187e-02,  ..., -1.2970e-02,\n",
       "             6.7139e-04,  1.5564e-02],\n",
       "           [ 3.5278e-02,  2.4811e-02,  1.8219e-02,  ..., -3.3386e-02,\n",
       "            -7.9041e-03,  1.7426e-02]],\n",
       "  \n",
       "          [[ 2.0660e-02,  1.5564e-02,  1.6205e-02,  ...,  6.5002e-02,\n",
       "             5.9540e-02,  5.4535e-02],\n",
       "           [-8.8501e-03, -1.8219e-02, -1.3977e-02,  ...,  6.9855e-02,\n",
       "             5.5878e-02,  4.4525e-02]],\n",
       "  \n",
       "          [[ 3.0518e-05, -9.1553e-05,  6.1035e-05,  ...,  5.1361e-02,\n",
       "             5.5206e-02,  5.7556e-02],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  8.6212e-02,\n",
       "             9.3018e-02,  1.0059e-01]],\n",
       "  \n",
       "          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -6.1035e-05,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -6.1035e-05,\n",
       "             0.0000e+00,  0.0000e+00]]]),\n",
       "  'vocals': tensor([[[ 2.1027e-02,  1.3794e-02, -5.7983e-03,  ...,  1.6382e-01,\n",
       "             1.5549e-01,  1.4780e-01],\n",
       "           [ 1.2665e-02, -2.7161e-03, -3.0334e-02,  ...,  1.3962e-01,\n",
       "             1.3269e-01,  1.2717e-01]],\n",
       "  \n",
       "          [[ 4.6722e-02,  2.0050e-02, -2.9358e-02,  ..., -2.6886e-02,\n",
       "            -4.2053e-02, -5.8472e-02],\n",
       "           [-9.5795e-02, -1.1133e-01, -9.5184e-02,  ...,  6.3629e-02,\n",
       "             7.7362e-02,  8.4045e-02]],\n",
       "  \n",
       "          [[-1.5259e-03, -4.0588e-03, -6.4392e-03,  ...,  2.3804e-03,\n",
       "             1.8616e-03,  3.6621e-04],\n",
       "           [-2.5330e-03, -3.2959e-03, -3.6621e-03,  ...,  1.6174e-03,\n",
       "             1.1292e-03, -1.5259e-04]],\n",
       "  \n",
       "          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00]]])}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_class(config.model.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model(input_channels=2, target_sources_num=len(config.dataset.sources))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1            [-1, 1025, 201]       2,099,200\n",
      "            Conv1d-2            [-1, 1025, 201]       2,099,200\n",
      "              STFT-3  [[-1, 1, 201, 1025], [-1, 1, 201, 1025]]               0\n",
      "       BatchNorm2d-4         [-1, 1025, 201, 2]           2,050\n",
      "       BatchNorm2d-5          [-1, 8, 256, 256]              16\n",
      "            Conv2d-6         [-1, 32, 256, 256]           2,304\n",
      "       BatchNorm2d-7         [-1, 32, 256, 256]              64\n",
      "            Conv2d-8         [-1, 32, 256, 256]           9,216\n",
      "            Conv2d-9         [-1, 32, 256, 256]             288\n",
      "     ConvBlockRes-10         [-1, 32, 256, 256]               0\n",
      "      BatchNorm2d-11         [-1, 32, 256, 256]              64\n",
      "           Conv2d-12         [-1, 32, 256, 256]           9,216\n",
      "      BatchNorm2d-13         [-1, 32, 256, 256]              64\n",
      "           Conv2d-14         [-1, 32, 256, 256]           9,216\n",
      "     ConvBlockRes-15         [-1, 32, 256, 256]               0\n",
      "      BatchNorm2d-16         [-1, 32, 256, 256]              64\n",
      "           Conv2d-17         [-1, 32, 256, 256]           9,216\n",
      "      BatchNorm2d-18         [-1, 32, 256, 256]              64\n",
      "           Conv2d-19         [-1, 32, 256, 256]           9,216\n",
      "     ConvBlockRes-20         [-1, 32, 256, 256]               0\n",
      "      BatchNorm2d-21         [-1, 32, 256, 256]              64\n",
      "           Conv2d-22         [-1, 32, 256, 256]           9,216\n",
      "      BatchNorm2d-23         [-1, 32, 256, 256]              64\n",
      "           Conv2d-24         [-1, 32, 256, 256]           9,216\n",
      "     ConvBlockRes-25         [-1, 32, 256, 256]               0\n",
      "EncoderBlockRes4B-26  [[-1, 32, 128, 128], [-1, 32, 256, 256]]               0\n",
      "      BatchNorm2d-27         [-1, 32, 128, 128]              64\n",
      "           Conv2d-28         [-1, 64, 128, 128]          18,432\n",
      "      BatchNorm2d-29         [-1, 64, 128, 128]             128\n",
      "           Conv2d-30         [-1, 64, 128, 128]          36,864\n",
      "           Conv2d-31         [-1, 64, 128, 128]           2,112\n",
      "     ConvBlockRes-32         [-1, 64, 128, 128]               0\n",
      "      BatchNorm2d-33         [-1, 64, 128, 128]             128\n",
      "           Conv2d-34         [-1, 64, 128, 128]          36,864\n",
      "      BatchNorm2d-35         [-1, 64, 128, 128]             128\n",
      "           Conv2d-36         [-1, 64, 128, 128]          36,864\n",
      "     ConvBlockRes-37         [-1, 64, 128, 128]               0\n",
      "      BatchNorm2d-38         [-1, 64, 128, 128]             128\n",
      "           Conv2d-39         [-1, 64, 128, 128]          36,864\n",
      "      BatchNorm2d-40         [-1, 64, 128, 128]             128\n",
      "           Conv2d-41         [-1, 64, 128, 128]          36,864\n",
      "     ConvBlockRes-42         [-1, 64, 128, 128]               0\n",
      "      BatchNorm2d-43         [-1, 64, 128, 128]             128\n",
      "           Conv2d-44         [-1, 64, 128, 128]          36,864\n",
      "      BatchNorm2d-45         [-1, 64, 128, 128]             128\n",
      "           Conv2d-46         [-1, 64, 128, 128]          36,864\n",
      "     ConvBlockRes-47         [-1, 64, 128, 128]               0\n",
      "EncoderBlockRes4B-48  [[-1, 64, 64, 64], [-1, 64, 128, 128]]               0\n",
      "      BatchNorm2d-49           [-1, 64, 64, 64]             128\n",
      "           Conv2d-50          [-1, 128, 64, 64]          73,728\n",
      "      BatchNorm2d-51          [-1, 128, 64, 64]             256\n",
      "           Conv2d-52          [-1, 128, 64, 64]         147,456\n",
      "           Conv2d-53          [-1, 128, 64, 64]           8,320\n",
      "     ConvBlockRes-54          [-1, 128, 64, 64]               0\n",
      "      BatchNorm2d-55          [-1, 128, 64, 64]             256\n",
      "           Conv2d-56          [-1, 128, 64, 64]         147,456\n",
      "      BatchNorm2d-57          [-1, 128, 64, 64]             256\n",
      "           Conv2d-58          [-1, 128, 64, 64]         147,456\n",
      "     ConvBlockRes-59          [-1, 128, 64, 64]               0\n",
      "      BatchNorm2d-60          [-1, 128, 64, 64]             256\n",
      "           Conv2d-61          [-1, 128, 64, 64]         147,456\n",
      "      BatchNorm2d-62          [-1, 128, 64, 64]             256\n",
      "           Conv2d-63          [-1, 128, 64, 64]         147,456\n",
      "     ConvBlockRes-64          [-1, 128, 64, 64]               0\n",
      "      BatchNorm2d-65          [-1, 128, 64, 64]             256\n",
      "           Conv2d-66          [-1, 128, 64, 64]         147,456\n",
      "      BatchNorm2d-67          [-1, 128, 64, 64]             256\n",
      "           Conv2d-68          [-1, 128, 64, 64]         147,456\n",
      "     ConvBlockRes-69          [-1, 128, 64, 64]               0\n",
      "EncoderBlockRes4B-70  [[-1, 128, 32, 32], [-1, 128, 64, 64]]               0\n",
      "      BatchNorm2d-71          [-1, 128, 32, 32]             256\n",
      "           Conv2d-72          [-1, 256, 32, 32]         294,912\n",
      "      BatchNorm2d-73          [-1, 256, 32, 32]             512\n",
      "           Conv2d-74          [-1, 256, 32, 32]         589,824\n",
      "           Conv2d-75          [-1, 256, 32, 32]          33,024\n",
      "     ConvBlockRes-76          [-1, 256, 32, 32]               0\n",
      "      BatchNorm2d-77          [-1, 256, 32, 32]             512\n",
      "           Conv2d-78          [-1, 256, 32, 32]         589,824\n",
      "      BatchNorm2d-79          [-1, 256, 32, 32]             512\n",
      "           Conv2d-80          [-1, 256, 32, 32]         589,824\n",
      "     ConvBlockRes-81          [-1, 256, 32, 32]               0\n",
      "      BatchNorm2d-82          [-1, 256, 32, 32]             512\n",
      "           Conv2d-83          [-1, 256, 32, 32]         589,824\n",
      "      BatchNorm2d-84          [-1, 256, 32, 32]             512\n",
      "           Conv2d-85          [-1, 256, 32, 32]         589,824\n",
      "     ConvBlockRes-86          [-1, 256, 32, 32]               0\n",
      "      BatchNorm2d-87          [-1, 256, 32, 32]             512\n",
      "           Conv2d-88          [-1, 256, 32, 32]         589,824\n",
      "      BatchNorm2d-89          [-1, 256, 32, 32]             512\n",
      "           Conv2d-90          [-1, 256, 32, 32]         589,824\n",
      "     ConvBlockRes-91          [-1, 256, 32, 32]               0\n",
      "EncoderBlockRes4B-92  [[-1, 256, 16, 16], [-1, 256, 32, 32]]               0\n",
      "      BatchNorm2d-93          [-1, 256, 16, 16]             512\n",
      "           Conv2d-94          [-1, 384, 16, 16]         884,736\n",
      "      BatchNorm2d-95          [-1, 384, 16, 16]             768\n",
      "           Conv2d-96          [-1, 384, 16, 16]       1,327,104\n",
      "           Conv2d-97          [-1, 384, 16, 16]          98,688\n",
      "     ConvBlockRes-98          [-1, 384, 16, 16]               0\n",
      "      BatchNorm2d-99          [-1, 384, 16, 16]             768\n",
      "          Conv2d-100          [-1, 384, 16, 16]       1,327,104\n",
      "     BatchNorm2d-101          [-1, 384, 16, 16]             768\n",
      "          Conv2d-102          [-1, 384, 16, 16]       1,327,104\n",
      "    ConvBlockRes-103          [-1, 384, 16, 16]               0\n",
      "     BatchNorm2d-104          [-1, 384, 16, 16]             768\n",
      "          Conv2d-105          [-1, 384, 16, 16]       1,327,104\n",
      "     BatchNorm2d-106          [-1, 384, 16, 16]             768\n",
      "          Conv2d-107          [-1, 384, 16, 16]       1,327,104\n",
      "    ConvBlockRes-108          [-1, 384, 16, 16]               0\n",
      "     BatchNorm2d-109          [-1, 384, 16, 16]             768\n",
      "          Conv2d-110          [-1, 384, 16, 16]       1,327,104\n",
      "     BatchNorm2d-111          [-1, 384, 16, 16]             768\n",
      "          Conv2d-112          [-1, 384, 16, 16]       1,327,104\n",
      "    ConvBlockRes-113          [-1, 384, 16, 16]               0\n",
      "EncoderBlockRes4B-114  [[-1, 384, 8, 8], [-1, 384, 16, 16]]               0\n",
      "     BatchNorm2d-115            [-1, 384, 8, 8]             768\n",
      "          Conv2d-116            [-1, 384, 8, 8]       1,327,104\n",
      "     BatchNorm2d-117            [-1, 384, 8, 8]             768\n",
      "          Conv2d-118            [-1, 384, 8, 8]       1,327,104\n",
      "    ConvBlockRes-119            [-1, 384, 8, 8]               0\n",
      "     BatchNorm2d-120            [-1, 384, 8, 8]             768\n",
      "          Conv2d-121            [-1, 384, 8, 8]       1,327,104\n",
      "     BatchNorm2d-122            [-1, 384, 8, 8]             768\n",
      "          Conv2d-123            [-1, 384, 8, 8]       1,327,104\n",
      "    ConvBlockRes-124            [-1, 384, 8, 8]               0\n",
      "     BatchNorm2d-125            [-1, 384, 8, 8]             768\n",
      "          Conv2d-126            [-1, 384, 8, 8]       1,327,104\n",
      "     BatchNorm2d-127            [-1, 384, 8, 8]             768\n",
      "          Conv2d-128            [-1, 384, 8, 8]       1,327,104\n",
      "    ConvBlockRes-129            [-1, 384, 8, 8]               0\n",
      "     BatchNorm2d-130            [-1, 384, 8, 8]             768\n",
      "          Conv2d-131            [-1, 384, 8, 8]       1,327,104\n",
      "     BatchNorm2d-132            [-1, 384, 8, 8]             768\n",
      "          Conv2d-133            [-1, 384, 8, 8]       1,327,104\n",
      "    ConvBlockRes-134            [-1, 384, 8, 8]               0\n",
      "EncoderBlockRes4B-135  [[-1, 384, 8, 4], [-1, 384, 8, 8]]               0\n",
      "     BatchNorm2d-136            [-1, 384, 8, 4]             768\n",
      "          Conv2d-137            [-1, 384, 8, 4]       1,327,104\n",
      "     BatchNorm2d-138            [-1, 384, 8, 4]             768\n",
      "          Conv2d-139            [-1, 384, 8, 4]       1,327,104\n",
      "    ConvBlockRes-140            [-1, 384, 8, 4]               0\n",
      "     BatchNorm2d-141            [-1, 384, 8, 4]             768\n",
      "          Conv2d-142            [-1, 384, 8, 4]       1,327,104\n",
      "     BatchNorm2d-143            [-1, 384, 8, 4]             768\n",
      "          Conv2d-144            [-1, 384, 8, 4]       1,327,104\n",
      "    ConvBlockRes-145            [-1, 384, 8, 4]               0\n",
      "     BatchNorm2d-146            [-1, 384, 8, 4]             768\n",
      "          Conv2d-147            [-1, 384, 8, 4]       1,327,104\n",
      "     BatchNorm2d-148            [-1, 384, 8, 4]             768\n",
      "          Conv2d-149            [-1, 384, 8, 4]       1,327,104\n",
      "    ConvBlockRes-150            [-1, 384, 8, 4]               0\n",
      "     BatchNorm2d-151            [-1, 384, 8, 4]             768\n",
      "          Conv2d-152            [-1, 384, 8, 4]       1,327,104\n",
      "     BatchNorm2d-153            [-1, 384, 8, 4]             768\n",
      "          Conv2d-154            [-1, 384, 8, 4]       1,327,104\n",
      "    ConvBlockRes-155            [-1, 384, 8, 4]               0\n",
      "EncoderBlockRes4B-156  [[-1, 384, 8, 4], [-1, 384, 8, 4]]               0\n",
      "     BatchNorm2d-157            [-1, 384, 8, 4]             768\n",
      "          Conv2d-158            [-1, 384, 8, 4]       1,327,104\n",
      "     BatchNorm2d-159            [-1, 384, 8, 4]             768\n",
      "          Conv2d-160            [-1, 384, 8, 4]       1,327,104\n",
      "    ConvBlockRes-161            [-1, 384, 8, 4]               0\n",
      "     BatchNorm2d-162            [-1, 384, 8, 4]             768\n",
      "          Conv2d-163            [-1, 384, 8, 4]       1,327,104\n",
      "     BatchNorm2d-164            [-1, 384, 8, 4]             768\n",
      "          Conv2d-165            [-1, 384, 8, 4]       1,327,104\n",
      "    ConvBlockRes-166            [-1, 384, 8, 4]               0\n",
      "     BatchNorm2d-167            [-1, 384, 8, 4]             768\n",
      "          Conv2d-168            [-1, 384, 8, 4]       1,327,104\n",
      "     BatchNorm2d-169            [-1, 384, 8, 4]             768\n",
      "          Conv2d-170            [-1, 384, 8, 4]       1,327,104\n",
      "    ConvBlockRes-171            [-1, 384, 8, 4]               0\n",
      "     BatchNorm2d-172            [-1, 384, 8, 4]             768\n",
      "          Conv2d-173            [-1, 384, 8, 4]       1,327,104\n",
      "     BatchNorm2d-174            [-1, 384, 8, 4]             768\n",
      "          Conv2d-175            [-1, 384, 8, 4]       1,327,104\n",
      "    ConvBlockRes-176            [-1, 384, 8, 4]               0\n",
      "EncoderBlockRes4B-177  [[-1, 384, 8, 4], [-1, 384, 8, 4]]               0\n",
      "     BatchNorm2d-178            [-1, 384, 8, 4]             768\n",
      "          Conv2d-179            [-1, 384, 8, 4]       1,327,104\n",
      "     BatchNorm2d-180            [-1, 384, 8, 4]             768\n",
      "          Conv2d-181            [-1, 384, 8, 4]       1,327,104\n",
      "    ConvBlockRes-182            [-1, 384, 8, 4]               0\n",
      "     BatchNorm2d-183            [-1, 384, 8, 4]             768\n",
      "          Conv2d-184            [-1, 384, 8, 4]       1,327,104\n",
      "     BatchNorm2d-185            [-1, 384, 8, 4]             768\n",
      "          Conv2d-186            [-1, 384, 8, 4]       1,327,104\n",
      "    ConvBlockRes-187            [-1, 384, 8, 4]               0\n",
      "     BatchNorm2d-188            [-1, 384, 8, 4]             768\n",
      "          Conv2d-189            [-1, 384, 8, 4]       1,327,104\n",
      "     BatchNorm2d-190            [-1, 384, 8, 4]             768\n",
      "          Conv2d-191            [-1, 384, 8, 4]       1,327,104\n",
      "    ConvBlockRes-192            [-1, 384, 8, 4]               0\n",
      "     BatchNorm2d-193            [-1, 384, 8, 4]             768\n",
      "          Conv2d-194            [-1, 384, 8, 4]       1,327,104\n",
      "     BatchNorm2d-195            [-1, 384, 8, 4]             768\n",
      "          Conv2d-196            [-1, 384, 8, 4]       1,327,104\n",
      "    ConvBlockRes-197            [-1, 384, 8, 4]               0\n",
      "EncoderBlockRes4B-198  [[-1, 384, 8, 4], [-1, 384, 8, 4]]               0\n",
      "     BatchNorm2d-199            [-1, 384, 8, 4]             768\n",
      "          Conv2d-200            [-1, 384, 8, 4]       1,327,104\n",
      "     BatchNorm2d-201            [-1, 384, 8, 4]             768\n",
      "          Conv2d-202            [-1, 384, 8, 4]       1,327,104\n",
      "    ConvBlockRes-203            [-1, 384, 8, 4]               0\n",
      "     BatchNorm2d-204            [-1, 384, 8, 4]             768\n",
      "          Conv2d-205            [-1, 384, 8, 4]       1,327,104\n",
      "     BatchNorm2d-206            [-1, 384, 8, 4]             768\n",
      "          Conv2d-207            [-1, 384, 8, 4]       1,327,104\n",
      "    ConvBlockRes-208            [-1, 384, 8, 4]               0\n",
      "     BatchNorm2d-209            [-1, 384, 8, 4]             768\n",
      "          Conv2d-210            [-1, 384, 8, 4]       1,327,104\n",
      "     BatchNorm2d-211            [-1, 384, 8, 4]             768\n",
      "          Conv2d-212            [-1, 384, 8, 4]       1,327,104\n",
      "    ConvBlockRes-213            [-1, 384, 8, 4]               0\n",
      "     BatchNorm2d-214            [-1, 384, 8, 4]             768\n",
      "          Conv2d-215            [-1, 384, 8, 4]       1,327,104\n",
      "     BatchNorm2d-216            [-1, 384, 8, 4]             768\n",
      "          Conv2d-217            [-1, 384, 8, 4]       1,327,104\n",
      "    ConvBlockRes-218            [-1, 384, 8, 4]               0\n",
      "EncoderBlockRes4B-219  [[-1, 384, 8, 4], [-1, 384, 8, 4]]               0\n",
      "     BatchNorm2d-220            [-1, 384, 8, 4]             768\n",
      " ConvTranspose2d-221            [-1, 384, 8, 8]         294,912\n",
      "     BatchNorm2d-222            [-1, 768, 8, 8]           1,536\n",
      "          Conv2d-223            [-1, 384, 8, 8]       2,654,208\n",
      "     BatchNorm2d-224            [-1, 384, 8, 8]             768\n",
      "          Conv2d-225            [-1, 384, 8, 8]       1,327,104\n",
      "          Conv2d-226            [-1, 384, 8, 8]         295,296\n",
      "    ConvBlockRes-227            [-1, 384, 8, 8]               0\n",
      "     BatchNorm2d-228            [-1, 384, 8, 8]             768\n",
      "          Conv2d-229            [-1, 384, 8, 8]       1,327,104\n",
      "     BatchNorm2d-230            [-1, 384, 8, 8]             768\n",
      "          Conv2d-231            [-1, 384, 8, 8]       1,327,104\n",
      "    ConvBlockRes-232            [-1, 384, 8, 8]               0\n",
      "     BatchNorm2d-233            [-1, 384, 8, 8]             768\n",
      "          Conv2d-234            [-1, 384, 8, 8]       1,327,104\n",
      "     BatchNorm2d-235            [-1, 384, 8, 8]             768\n",
      "          Conv2d-236            [-1, 384, 8, 8]       1,327,104\n",
      "    ConvBlockRes-237            [-1, 384, 8, 8]               0\n",
      "     BatchNorm2d-238            [-1, 384, 8, 8]             768\n",
      "          Conv2d-239            [-1, 384, 8, 8]       1,327,104\n",
      "     BatchNorm2d-240            [-1, 384, 8, 8]             768\n",
      "          Conv2d-241            [-1, 384, 8, 8]       1,327,104\n",
      "    ConvBlockRes-242            [-1, 384, 8, 8]               0\n",
      "DecoderBlockRes4B-243            [-1, 384, 8, 8]               0\n",
      "     BatchNorm2d-244            [-1, 384, 8, 8]             768\n",
      " ConvTranspose2d-245          [-1, 384, 16, 16]         589,824\n",
      "     BatchNorm2d-246          [-1, 768, 16, 16]           1,536\n",
      "          Conv2d-247          [-1, 384, 16, 16]       2,654,208\n",
      "     BatchNorm2d-248          [-1, 384, 16, 16]             768\n",
      "          Conv2d-249          [-1, 384, 16, 16]       1,327,104\n",
      "          Conv2d-250          [-1, 384, 16, 16]         295,296\n",
      "    ConvBlockRes-251          [-1, 384, 16, 16]               0\n",
      "     BatchNorm2d-252          [-1, 384, 16, 16]             768\n",
      "          Conv2d-253          [-1, 384, 16, 16]       1,327,104\n",
      "     BatchNorm2d-254          [-1, 384, 16, 16]             768\n",
      "          Conv2d-255          [-1, 384, 16, 16]       1,327,104\n",
      "    ConvBlockRes-256          [-1, 384, 16, 16]               0\n",
      "     BatchNorm2d-257          [-1, 384, 16, 16]             768\n",
      "          Conv2d-258          [-1, 384, 16, 16]       1,327,104\n",
      "     BatchNorm2d-259          [-1, 384, 16, 16]             768\n",
      "          Conv2d-260          [-1, 384, 16, 16]       1,327,104\n",
      "    ConvBlockRes-261          [-1, 384, 16, 16]               0\n",
      "     BatchNorm2d-262          [-1, 384, 16, 16]             768\n",
      "          Conv2d-263          [-1, 384, 16, 16]       1,327,104\n",
      "     BatchNorm2d-264          [-1, 384, 16, 16]             768\n",
      "          Conv2d-265          [-1, 384, 16, 16]       1,327,104\n",
      "    ConvBlockRes-266          [-1, 384, 16, 16]               0\n",
      "DecoderBlockRes4B-267          [-1, 384, 16, 16]               0\n",
      "     BatchNorm2d-268          [-1, 384, 16, 16]             768\n",
      " ConvTranspose2d-269          [-1, 256, 32, 32]         393,216\n",
      "     BatchNorm2d-270          [-1, 512, 32, 32]           1,024\n",
      "          Conv2d-271          [-1, 256, 32, 32]       1,179,648\n",
      "     BatchNorm2d-272          [-1, 256, 32, 32]             512\n",
      "          Conv2d-273          [-1, 256, 32, 32]         589,824\n",
      "          Conv2d-274          [-1, 256, 32, 32]         131,328\n",
      "    ConvBlockRes-275          [-1, 256, 32, 32]               0\n",
      "     BatchNorm2d-276          [-1, 256, 32, 32]             512\n",
      "          Conv2d-277          [-1, 256, 32, 32]         589,824\n",
      "     BatchNorm2d-278          [-1, 256, 32, 32]             512\n",
      "          Conv2d-279          [-1, 256, 32, 32]         589,824\n",
      "    ConvBlockRes-280          [-1, 256, 32, 32]               0\n",
      "     BatchNorm2d-281          [-1, 256, 32, 32]             512\n",
      "          Conv2d-282          [-1, 256, 32, 32]         589,824\n",
      "     BatchNorm2d-283          [-1, 256, 32, 32]             512\n",
      "          Conv2d-284          [-1, 256, 32, 32]         589,824\n",
      "    ConvBlockRes-285          [-1, 256, 32, 32]               0\n",
      "     BatchNorm2d-286          [-1, 256, 32, 32]             512\n",
      "          Conv2d-287          [-1, 256, 32, 32]         589,824\n",
      "     BatchNorm2d-288          [-1, 256, 32, 32]             512\n",
      "          Conv2d-289          [-1, 256, 32, 32]         589,824\n",
      "    ConvBlockRes-290          [-1, 256, 32, 32]               0\n",
      "DecoderBlockRes4B-291          [-1, 256, 32, 32]               0\n",
      "     BatchNorm2d-292          [-1, 256, 32, 32]             512\n",
      " ConvTranspose2d-293          [-1, 128, 64, 64]         131,072\n",
      "     BatchNorm2d-294          [-1, 256, 64, 64]             512\n",
      "          Conv2d-295          [-1, 128, 64, 64]         294,912\n",
      "     BatchNorm2d-296          [-1, 128, 64, 64]             256\n",
      "          Conv2d-297          [-1, 128, 64, 64]         147,456\n",
      "          Conv2d-298          [-1, 128, 64, 64]          32,896\n",
      "    ConvBlockRes-299          [-1, 128, 64, 64]               0\n",
      "     BatchNorm2d-300          [-1, 128, 64, 64]             256\n",
      "          Conv2d-301          [-1, 128, 64, 64]         147,456\n",
      "     BatchNorm2d-302          [-1, 128, 64, 64]             256\n",
      "          Conv2d-303          [-1, 128, 64, 64]         147,456\n",
      "    ConvBlockRes-304          [-1, 128, 64, 64]               0\n",
      "     BatchNorm2d-305          [-1, 128, 64, 64]             256\n",
      "          Conv2d-306          [-1, 128, 64, 64]         147,456\n",
      "     BatchNorm2d-307          [-1, 128, 64, 64]             256\n",
      "          Conv2d-308          [-1, 128, 64, 64]         147,456\n",
      "    ConvBlockRes-309          [-1, 128, 64, 64]               0\n",
      "     BatchNorm2d-310          [-1, 128, 64, 64]             256\n",
      "          Conv2d-311          [-1, 128, 64, 64]         147,456\n",
      "     BatchNorm2d-312          [-1, 128, 64, 64]             256\n",
      "          Conv2d-313          [-1, 128, 64, 64]         147,456\n",
      "    ConvBlockRes-314          [-1, 128, 64, 64]               0\n",
      "DecoderBlockRes4B-315          [-1, 128, 64, 64]               0\n",
      "     BatchNorm2d-316          [-1, 128, 64, 64]             256\n",
      " ConvTranspose2d-317         [-1, 64, 128, 128]          32,768\n",
      "     BatchNorm2d-318        [-1, 128, 128, 128]             256\n",
      "          Conv2d-319         [-1, 64, 128, 128]          73,728\n",
      "     BatchNorm2d-320         [-1, 64, 128, 128]             128\n",
      "          Conv2d-321         [-1, 64, 128, 128]          36,864\n",
      "          Conv2d-322         [-1, 64, 128, 128]           8,256\n",
      "    ConvBlockRes-323         [-1, 64, 128, 128]               0\n",
      "     BatchNorm2d-324         [-1, 64, 128, 128]             128\n",
      "          Conv2d-325         [-1, 64, 128, 128]          36,864\n",
      "     BatchNorm2d-326         [-1, 64, 128, 128]             128\n",
      "          Conv2d-327         [-1, 64, 128, 128]          36,864\n",
      "    ConvBlockRes-328         [-1, 64, 128, 128]               0\n",
      "     BatchNorm2d-329         [-1, 64, 128, 128]             128\n",
      "          Conv2d-330         [-1, 64, 128, 128]          36,864\n",
      "     BatchNorm2d-331         [-1, 64, 128, 128]             128\n",
      "          Conv2d-332         [-1, 64, 128, 128]          36,864\n",
      "    ConvBlockRes-333         [-1, 64, 128, 128]               0\n",
      "     BatchNorm2d-334         [-1, 64, 128, 128]             128\n",
      "          Conv2d-335         [-1, 64, 128, 128]          36,864\n",
      "     BatchNorm2d-336         [-1, 64, 128, 128]             128\n",
      "          Conv2d-337         [-1, 64, 128, 128]          36,864\n",
      "    ConvBlockRes-338         [-1, 64, 128, 128]               0\n",
      "DecoderBlockRes4B-339         [-1, 64, 128, 128]               0\n",
      "     BatchNorm2d-340         [-1, 64, 128, 128]             128\n",
      " ConvTranspose2d-341         [-1, 32, 256, 256]           8,192\n",
      "     BatchNorm2d-342         [-1, 64, 256, 256]             128\n",
      "          Conv2d-343         [-1, 32, 256, 256]          18,432\n",
      "     BatchNorm2d-344         [-1, 32, 256, 256]              64\n",
      "          Conv2d-345         [-1, 32, 256, 256]           9,216\n",
      "          Conv2d-346         [-1, 32, 256, 256]           2,080\n",
      "    ConvBlockRes-347         [-1, 32, 256, 256]               0\n",
      "     BatchNorm2d-348         [-1, 32, 256, 256]              64\n",
      "          Conv2d-349         [-1, 32, 256, 256]           9,216\n",
      "     BatchNorm2d-350         [-1, 32, 256, 256]              64\n",
      "          Conv2d-351         [-1, 32, 256, 256]           9,216\n",
      "    ConvBlockRes-352         [-1, 32, 256, 256]               0\n",
      "     BatchNorm2d-353         [-1, 32, 256, 256]              64\n",
      "          Conv2d-354         [-1, 32, 256, 256]           9,216\n",
      "     BatchNorm2d-355         [-1, 32, 256, 256]              64\n",
      "          Conv2d-356         [-1, 32, 256, 256]           9,216\n",
      "    ConvBlockRes-357         [-1, 32, 256, 256]               0\n",
      "     BatchNorm2d-358         [-1, 32, 256, 256]              64\n",
      "          Conv2d-359         [-1, 32, 256, 256]           9,216\n",
      "     BatchNorm2d-360         [-1, 32, 256, 256]              64\n",
      "          Conv2d-361         [-1, 32, 256, 256]           9,216\n",
      "    ConvBlockRes-362         [-1, 32, 256, 256]               0\n",
      "DecoderBlockRes4B-363         [-1, 32, 256, 256]               0\n",
      "     BatchNorm2d-364         [-1, 32, 256, 256]              64\n",
      "          Conv2d-365         [-1, 32, 256, 256]           9,216\n",
      "     BatchNorm2d-366         [-1, 32, 256, 256]              64\n",
      "          Conv2d-367         [-1, 32, 256, 256]           9,216\n",
      "    ConvBlockRes-368         [-1, 32, 256, 256]               0\n",
      "     BatchNorm2d-369         [-1, 32, 256, 256]              64\n",
      "          Conv2d-370         [-1, 32, 256, 256]           9,216\n",
      "     BatchNorm2d-371         [-1, 32, 256, 256]              64\n",
      "          Conv2d-372         [-1, 32, 256, 256]           9,216\n",
      "    ConvBlockRes-373         [-1, 32, 256, 256]               0\n",
      "     BatchNorm2d-374         [-1, 32, 256, 256]              64\n",
      "          Conv2d-375         [-1, 32, 256, 256]           9,216\n",
      "     BatchNorm2d-376         [-1, 32, 256, 256]              64\n",
      "          Conv2d-377         [-1, 32, 256, 256]           9,216\n",
      "    ConvBlockRes-378         [-1, 32, 256, 256]               0\n",
      "     BatchNorm2d-379         [-1, 32, 256, 256]              64\n",
      "          Conv2d-380         [-1, 32, 256, 256]           9,216\n",
      "     BatchNorm2d-381         [-1, 32, 256, 256]              64\n",
      "          Conv2d-382         [-1, 32, 256, 256]           9,216\n",
      "    ConvBlockRes-383         [-1, 32, 256, 256]               0\n",
      "EncoderBlockRes4B-384  [[-1, 32, 256, 256], [-1, 32, 256, 256]]               0\n",
      "          Conv2d-385        [-1, 128, 256, 256]           4,224\n",
      "          Conv1d-386            [-1, 2048, 201]       4,194,304\n",
      "          Conv1d-387            [-1, 2048, 201]       4,194,304\n",
      "           ISTFT-388                [-1, 88200]               0\n",
      "================================================================\n",
      "Total params: 115,164,178\n",
      "Trainable params: 102,577,170\n",
      "Non-trainable params: 12,587,008\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.67\n",
      "Forward/backward pass size (MB): 45042943.05\n",
      "Params size (MB): 439.32\n",
      "Estimated Total Size (MB): 45043383.04\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model=model, input_size=(2, 44100*2), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3330)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = torchmetrics.regression.MeanAbsoluteError()\n",
    "loss_fn(torch.rand((1,2,44100)), torch.rand((1,2,44100)))  # This needs to be done for each target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFn(nn.Module):\n",
    "    def __init__(self, function, order=['bass', 'drums', 'other', 'vocals']):\n",
    "        super().__init__()\n",
    "        self.function = function\n",
    "        self.order = order\n",
    "\n",
    "    def forward(self, sources, targets):\n",
    "        sum_ls = 0\n",
    "        if type(sources)==list:\n",
    "            for source, target in zip(sources, targets):\n",
    "                sum_ls += self.function(source, target)\n",
    "            sum_ls /= len(sources)\n",
    "        else:\n",
    "            sum_ls = self.function(sources, targets)\n",
    "        return sum_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3333)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = LossFn(torchmetrics.regression.MeanAbsoluteError())\n",
    "loss_fn([torch.rand((1,2,44100)) for i in range(4)], [torch.rand((1,2,44100)) for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0894)\n"
     ]
    }
   ],
   "source": [
    "## One forward pass\n",
    "model.eval()\n",
    "inp = next(iter(dl))\n",
    "# inp['input'].shape, torch.tensor(np.hstack(next(iter(dl))['output'].values())).shape\n",
    "with torch.no_grad():\n",
    "    out = model(inp['input'])\n",
    "print(loss_fn(torch.tensor(np.hstack(list(next(iter(dl))['output'].values()))), out['waveform']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0372, -0.0382, -0.0393, -0.0404, -0.0415, -0.0427, -0.0439,\n",
       "           -0.0451, -0.0463, -0.0475]]]),\n",
       " tensor([[[ 0.0756,  0.1533,  0.0892,  0.0506, -0.0041, -0.0062,  0.0128,\n",
       "            0.0567,  0.0569,  0.0717]]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(np.hstack(list(next(iter(dl))['output'].values())))[:1,:1,:10], out['waveform'][ :1, :1, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_lambda(step, warm_up_steps: int, reduce_lr_steps: int):\n",
    "    r\"\"\"Get lr_lambda for LambdaLR. E.g.,\n",
    "\n",
    "    .. code-block: python\n",
    "        lr_lambda = lambda step: get_lr_lambda(step, warm_up_steps=1000, reduce_lr_steps=10000)\n",
    "\n",
    "        from torch.optim.lr_scheduler import LambdaLR\n",
    "        LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "    Args:\n",
    "        warm_up_steps: int, steps for warm up\n",
    "        reduce_lr_steps: int, reduce learning rate by 0.9 every #reduce_lr_steps steps\n",
    "\n",
    "    Returns:\n",
    "        learning rate: float\n",
    "    \"\"\"\n",
    "    if step <= warm_up_steps:\n",
    "        return step / warm_up_steps\n",
    "    else:\n",
    "        return 0.9 ** (step // reduce_lr_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams definition\n",
    "n_steps = 5000\n",
    "optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=1e-3,\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-08,\n",
    "            weight_decay=0.0,\n",
    "            amsgrad=True,\n",
    "        )\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step is 0:   0%|          | 0/5000 [00:41<?, ?it/s]\n",
      "Step is 0:   0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(range(n_steps))\n",
    "metric = {\n",
    "    \"sdr\": SignalDistortionRatio(),\n",
    "    \"snr\": SignalNoiseRatio(),\n",
    "    \"sisdr\": ScaleInvariantSignalDistortionRatio()\n",
    "}\n",
    "device = config.device\n",
    "\n",
    "losses = []\n",
    "for epoch in range(n_steps):\n",
    "    progress_bar.set_description(f\"Step is {epoch}\")\n",
    "    model.train()\n",
    "    train_score = [0]\n",
    "    for bid, batch in enumerate(dl):\n",
    "        input_wave = batch['input'].to(device)\n",
    "        target_waves = torch.tensor(np.hstack([batch['output'][i] for i in config.dataset.targets]))\n",
    "\n",
    "        model.zero_grad()\n",
    "        outputs = model(input_wave)['waveform']\n",
    "        loss = loss_fn(target_waves, outputs)\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        ts_score = metric['sdr'](target_waves, outputs)\n",
    "        train_score.append(ts_score)\n",
    "        print(loss.item(), np.mean(train_score))\n",
    "        progress_bar.set_postfix(loss=f\"{loss.item()}\", Training=f\"{np.mean(train_score)}\")\n",
    "        progress_bar.update(1)\n",
    "    progress_bar.close()\n",
    "        # break\n",
    "    break\n",
    "        \n",
    "#         if bid%500==0:\n",
    "#             scores=[0]\n",
    "#             model.eval()\n",
    "#             for batch in dl:\n",
    "#                 batch = {k: v.to(device) for k, v in batch.items()}\n",
    "#                 with torch.no_grad():\n",
    "#                     outputs = model(**batch)\n",
    "\n",
    "#                 logits = outputs.logits\n",
    "#                 predictions = outputs.logits.argmax(-1)\n",
    "#                 fscore = f1_score(logits.argmax(-1).detach().cpu().numpy().reshape(-1), \n",
    "#                          batch[\"labels\"].cpu().numpy().reshape(-1), \n",
    "#                          average=f1_avg)\n",
    "# #                 fscore = flat_accuracy(logits.argmax(-1).detach().cpu().numpy().reshape(-1), \n",
    "# #                                        batch[\"labels\"].cpu().numpy().reshape(-1))\n",
    "#                 scores.append(fscore)\n",
    "#                 progress_bar.set_postfix(loss=loss.item(), Training=np.mean(train_score), Testing=np.mean(scores))\n",
    "#             model.train()\n",
    "# print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a13e682a027a7edbf8d4fdbcc36884d648dd4d8c211398dc10e8ff744b4f2a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
